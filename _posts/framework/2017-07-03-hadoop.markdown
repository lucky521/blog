---
title: "Hadoop使用手册"
categories: [framework]
layout: post
---

# Hadoop概念

分布式。数据存储。数据处理。

Hadoop主要由HDFS + YARN + MapReduce三个核心组件组成。
* HDFS是一个文件系统，负责分布式存储；
* YARN是Hadoop自带的一个通用的资源管理框架，用来对跑在集群上的Application进行资源分配及管理；
* MapReduce是一个分布式计算框架，跑在YARN上，配合HDFS用来做分布式数据计算。

## NameNode 进程
NameNode只有一个，它是整个HDFS的核心。分布式文件系统的管理者。当然也是HDFS的一个单点瓶颈，如果它挂掉，HDFS就会崩溃，所以对它的保护尤为重要。
secondarynamenode进程是NameNode的冗余进程。
此节点的内存配置要高，因为存储元信息都直接加载在内存里。
特殊的情况：配置多个NameNode，配置多个namenode的相当于配置了一个联邦集群，每个namenode之间都不会进行通信，各自管理各自的命名空间。

## DataNode进程
文件存储的基本单元。每个节点运行一个。应用程序才访问文件系统时，先由NameNode提供数据的位置，然后程序去访问对应的DataNode。
datanode启动时，每个datanode对本地磁盘进行扫描，将本datanode上保存的block信息汇报给namenode, namenode在接收到的block信息以及该block所在的datanode信息等保存在内存中。
此类节点的硬盘配置要大，因为真实的数据都存在这里。

## JobTracker进程
在MR1中有个jobtracker的进程，运行在单独的节点。 MR2中被ResourceManager/ApplicationMaster替代。
1、应用程序将job提交给JobTracker
2、JobTracker通知NameNode，让其确定数据的位置
3、JobTracker确定TaskTacker节点，将work提交给确定好的TaskTracker
4、TaskTracker一直被JobTracker监控着，如果不按时返回心跳信号或者主动返回失败，则认为是执行失败，将会转向其他TaskTracker。
5、当work顺利执行完毕，JobTracker更新状态
6、应用程序可以轮询JobTracker的状态

## TaskTracker进程
MR2中被Node Manager替代。
task指的是Map/Reduce/Shuffle操作。
每个TaskTracker都有一个slot集来标记这个TaskTracker所能接受的task的个数。当JobTracker要分配一个task时，会在DataNode的就近节点中找一个空的slot，把task分配给对应的TaskTracker。当TaskTracker要处理一个task时，会产生一个新的进程来执行它。在执行期间不断向JobTracker发回心跳信号，执行完毕返回结果。


## Container
Yarn将计算资源（cpu、内存）封装成一个个的容器。容器由NodeManager管理。被ResourceManager调度。





## speculative execution
Hadoop 前端页面可以看到一个 speculate 按钮。
https://data-flair.training/forums/topic/what-is-speculative-execution-in-hadoop/



# Linux下安装和启动Hadoop

### 添加用户和用户组

```
> sudo addgroup hadoop
> sudo adduser --ingroup hadoop hduser
```

### 开启ssh连接（要为Hadoop集群中的所有机器提供SSH授权）

```
> ssh hduser@localhost
```


### Disable IPV6
```s
> sudo vim /etc/sysctl.conf
add
# disable ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
```

### 安装hadoop

```s
> sudo add-apt-repository ppa:hadoop-ubuntu/stable
> sudo apt-get update && sudo apt-get upgrade  
> sudo apt-get install hadoop
> man hadoop
```

### 设置环境变量

```s
> sudo vim /home/hduser/.bashrc
# Set Hadoop-related environment variables   设置hadoop程序的路径，这样程序找自带jar包也容易。
export HADOOP_HOME=/usr/lib/hadoop
# Set JAVA_HOME (we will also configure JAVA_HOME directly for Hadoop later on)  设置JDK的路径
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
```

### 修改conf/hadoop-env.sh

```s
$ sudo vim /etc/hadoop/conf/hadoop-env.sh
add
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
```

### 给HDFS文件系统创建一个目录

HDFS文件系统的权限属于hduser
```s
$ sudo mkdir -p /app/hadoop/tmp
$ sudo chown hduser:hadoop /app/hadoop/tmp
# ...and if you want to tighten up security, chmod from 755 to 750...
$ sudo chmod 750 /app/hadoop/tmp
```

### 填写conf/core-site.xml

```s
$ sudo vim /etc/hadoop/conf/core-site.xml
```
填写了hadoop.tmp.dir的path， fs.default.name的link

### 填写conf/mapred-site.xml

```s
$ sudo vim /etc/hadoop/conf/mapred-site.xml
```
填写了mapred.job.tracker的link地址（唯一的JobTracker主服务器地址）

### 填写conf/hdfs-site.xml

```
$ sudo vim /etc/hadoop/conf/hdfs-site.xml
设置了dfs.replication的值为1。
```

### 格式化HDFS文件系统
以hduser的身份进行操作
```
$ hadoop namenode -format
```
这样就在/app/hadoop/tmp下创建了一个空的文件系统。

### 启动Hadoop
```
> /usr/lib/hadoop/bin/start-all.sh
```
这就会启动a Namenode, SecondaryNameNode, Datanode, Jobtracker and a Tasktracker

### 查看java 进程
```
> jps
```
看到5个进程都启动起来了。


# MacOSX下安装和启动Hadoop

- 1、先安装java （上官网下载安装包）
- 2、已经自带了ssh。
打开hadoop的时候不要连接外网。连外网之后本机ip就变了。ssh到localhost出错。需要去System Preferences的Sharing里面手动允许22端口开放：http://stackoverflow.com/questions/6313929/how-do-i-open-port-22-in-osx-10-6-7
- 3、brew install hadoop 直接安装了1.2.1稳定版
```
hadoop version 查看版本号
```
hadoop系统安装路径在
```
/usr/local/Cellar/hadoop/1.2.1/
```


## 填写配置文件：
三大配置文件，core-site.xml, hdfs-site.xml, mapred-site.xml (在0.2老版本中是三合一的一个xml)。要分别在里面填写name、jobtracker、replication的配置内容。

默认的配置文件路径在 $HADOOP_CONF_DIR下。

## 格式化一个新的文件系统（在hadoop所有进程关闭的时候运行这个）
```
$ hadoop namenode -format
```
默认情况下这个文件系统hdfs被放在本机的/tmp/hadoop-liulu/。对于hdfs本身来说，其中的文件被放在/user/liulu里面。





# Hadoop的启动与配置

## hadoop启动与关闭
```s
> start-all.sh  全体node启动
启动hadoop的五个默认进程，
> stop-all.sh 关闭hadoop的五个默认进程，他们都运行在JVM之上。
77857 SecondaryNameNode
77659 NameNode
77930 JobTracker
78028 TaskTracker
77758 DataNode
```

## 配置文件

/etc/hadoop/conf
https://hadoop.apache.org/docs/r1.0.4/hdfs-default.html

core-site.xml
- 必须在所有master及slave上的conf/core-site.xml中设置fs.default.name项。并且因为Hadoop架构是主master模式，所以在一个集群中的所有master及slave上设置的fs.default.name值应该是唯一一个NameNode 主服务器的地址。
- 为每个node上的HDFS系统设置文件系统在本机的路径，hadoop.tmp.dir。

hdfs-site.xml
- 设置dfs.replication，即hdfs数据块的复制份数，默认3。
- 可以设置dfs.name.dir来改变Namenoode的存储位置，也可以不改，默认就在hadoop.tmp.dir下面。
- 可以设置dfs.data.dir来改变Datanoode的存储位置，也可以不改，默认就在hadoop.tmp.dir下面。

mapred-site.xml
- 必须在所有master及slave上的conf/mapred-site.xml中设置mapred.job.tracker项。并且因为Hadoop架构是主master模式，所以在一个集群中的所有master及slave上设置的mapred.job.tracker的值应该是唯一一个JobTracker主服务器的地址。

mapred-queue-acls.xml
- mapred.queue.<queue-name>.acl-submit-job ， List of users and groups that can submit jobs to the specified queue-name.
- mapred.queue.<queue-name>.acl-administer-jobs， List of users and groups that can view job details, change the priority or kill jobs that have been submitted to the specified queue-name.

/etc/hadoop/conf/hadoop-site.xml ？？？

/etc/hadoop/conf/hadoop-env.xml ？？？


## 主要可执行文件
/usr/lib/hadoop


## 单独node启动脚本
启动/停止NameNode
/etc/init.d/hadoop-namenode
启动/停止DataNode
/etc/init.d/hadoop-datanode
启动/停止Secondary NameNode
/etc/init.d/hadoop-secondarynamenode
启动/停止jobtracker
/etc/init.d/hadoop-jobtracker
启动/停止tasktracker
/etc/init.d/hadoop-tasktracker


## 默认的web可视化监控页面
对job tracker的监控  http://10.117.175.50:50030/
对NameNode的监控  http://10.117.175.50:50070/
对task tracker的监控 http://10.117.175.50:50060/


## 日志文件
放在/usr/lib/hadoop/logs



# 管理接口

| 50010 | dfs.datanode.address，DataNode的数据传输端口 |

https://intl.cloud.tencent.com/zh/document/product/1026/36880#hdfs-datanode







# HDFS文件系统
是一个虚拟的文件系统。
home目录叫做" /user/hduser"（hduser是为hadoop专门添加的一个用户）


## 文件的组织

data block，  HDFS文件会被切成一般128MB的块。



# 参考

[不同hadoop版本最权威的文档](https://hadoop.apache.org/docs/)

[官方架构文档](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)