---
title: "Flink开发实践"
categories: [framework]
layout: post
---

# 流式数据处理概念

## 为什么选Flink？

如果你对大数据流式处理有以下需求，
* 乱序数据流有序化处理
* 处理过程有状态
* 处理过程容错，需无缝从失败中恢复
* 超大数据规模(需分布式支持)
* 期望用一套框架支持批式处理和流式处理
那么可供你选择的成熟框架并不多。


## Google Dataflow
批流一体的理论基石。

## 基本概念

本地状态，存储中间信息、缓存信息。

窗口操作

事件驱动

管道 允许输入流数据，输出流数据，交给下一个任务

DAG

数据传递方式
hash / rebalance / forward / shuffle / rescale

Exactly-Once
Exactly-Once是流处理系统核心特性之一，它保证每一条消息只被流处理系统处理一次，通过借鉴Chandy和Lamport在1985年发表的一篇关于分布式快照的论文，Flink实现了Exactly-Once特性。

JobGraph
JobGraph是通过 Flink 各类API构建起来的一张任务执行图。 当 JobGraph 提交给 Flink 集群后，能够以 Local、Standalone、Yarn 和 Kubernetes 四种模式运行。

### JobManager
JobManager 相当于整个集群的 Master 节点，且整个集群有且只有一个活跃的 JobManager ，负责整个集群的任务管理和资源管理。

### TaskManager 
TaskManager 相当于整个集群的 Slave 节点，负责具体的任务执行和对应任务在每个节点上的资源申请和管理。一个TM对应一个JVM。


Task slot
任务槽是Flink计算资源的基本单位. Task Manager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。
每个任务槽可以在同一时间执行一个Task，而TaskManager可以拥有一个或者多个任务槽。
任务槽可以实现TaskManager中不同Task的资源隔离，不过是逻辑隔离，并且只隔离内存，亦即在调度层面认为每个任务槽“应该”得到taskmanager.heap.size的N分之一大小的内存。CPU资源不算在内。


## Checkpoint 和 Savepoint

Flink中的每个方法或算子都可以是由状态的。

这两者都是用于恢复作用。尤其是checkpoint用于恢复异常失败的作业。
* Checkpoint 是增量做的，每次的时间较短，数据量较小，只要在程序里面启用后会自动触发，用户无须感知；Checkpoint 是作业 failover 的时候自动使用，不需要用户指定。
* Savepoint 是全量做的，每次的时间较长，数据量较大，需要用户主动去触发。Savepoint 一般用于程序的版本更新，Bug 修复，A/B Test 等场景，需要用户指定。
- 概念比较 https://www.ververica.com/blog/differences-between-savepoints-and-checkpoints-in-flink
- CP原理介绍 https://www.infoq.cn/article/pb8pxvssiw2evebhpz7e ， https://juejin.cn/post/6844904147494371342
- CP使用介绍： https://ci.apache.org/projects/flink/flink-docs-master/zh/docs/dev/datastream/fault-tolerance/checkpointing/

Checkpoint的成本
Checkpoint在生成和恢复的时候都会消耗资源。
Checkpoint 里面存的是什么内容？ _metadata
Checkpoint 太大了怎么办？


作业 Failover
Checkpoint 在作业failover的时候自动使用。
Flink 的容错机制主要分为从 checkpoint 恢复状态和重流数据两步，这也是为什么 Flink 通常要求数据源的数据是可以重复读取的。对于重启后的新 Task 来说，它可以通过读取 checkpoint 很容易地恢复状态信息，但是却不能独立地重流数据，因为 checkpoint 是不包含数据的。

通过 Flink 配置文件 flink-conf.yaml 中的 jobmanager.execution.failover-strategy 配置项进行配置Failover策略：
1. 全图重启 full
2. 基于Region的局部重启 region


checkpoint失败原因
* 如果 Checkpoint 做的非常慢，超过了 timeout 还没有完成，则整个 Checkpoint 也会失败。 Checkpoint慢的原因需要细查。
* 用户代码逻辑没有对于异常处理，让其直接在运行中抛出。比如解析 Json 异常，没有捕获，导致 Checkpoint 失败，或者调用 Dubbo 超时异常等等。
* 依赖外部存储系统，在进行数据交互时，出错，异常没有处理。比如输出数据到 Kafka、Redis、HBase 等，客户端抛出了超时异常，没有进行捕获，Flink 任务容错机制会再次重启。
* 内存不足，频繁 GC，超出了 GC 负载的限制。比如 OOM 异常
* 网络问题、机器不可用问题等等。
- 参考：[Flink Checkpoint 问题排查实用指南](https://www.jianshu.com/p/fc100f85a0fb)

Checkpoint失败与作业失败的关联？

如何从checkpoint恢复启动作业？
常用的重启策略
    （1）固定间隔策略 (Fixed delay)
    （2）失败率策略 (Failure rate)
    （3）无重启 (No restart)


## Flink 单点恢复
https://segmentfault.com/a/1190000025168779




## Flink 与 HDFS

Flink和HDFS打交道主要有两类情况，一类是Checkpoint，一类是Hdfs-Sink

flink的cp会备份到hdfs去，当作业并发量大（TM多）时，HDFS的压力会大：
1）大量的 RPC 请求会影响 RPC 的响应时间；
2）大量文件对 NameNode 内存造成很大压力；
3) 大量产出小文件，其他任务读取小文件数据的成本也增加；

### 减小Checkpointing对HDFS的压力
参考：https://www.infoq.cn/article/OLlJNzQpTOHfyrgOG8xq

### HDFS-Sink避免小文件过多
* 减少并行度：回顾一下文件生成格式：part + subtaskIndex + connter，其中subtaskIndex代表着任务并行度的序号，也就是代表着当前的一个写task，越大的并行度代表着越多的subtaskIndex，数据就越分散，如果我们减小并行度，数据写入由更少的task来执行，写入就相对集中，这个在一定程度上减少的文件的个数，但是在减少并行的同时意味着任务的并发能力下降；
* 增大checkpoint周期或者文件滚动周期：以parquet写分析为例，parquet写文件由processing状态变为pending状态发生在checkpoint的snapshotState阶段中，如果checkpoint周期时间较短，就会更快发生文件滚动，增大checkpoint周期，那么文件就能积累更多数据之后发生滚动，但是这种增加时间的方式带来的是数据的一定延时；
* 下游任务合并处理：待Flink将数据写入hdfs后，下游开启一个hive或者spark定时任务，通过改变分区的方式，将文件写入新的目录中，后续任务处理读取这个新的目录数据即可，同时还需要定时清理产生的小文件，这种方式虽然增加了后续的任务处理成本，但是其即合并了小文件提升了后续任务分析速度，也将小文件清理了减小了对NameNode的压力，相对于上面两种方式更加稳定，因此也比较推荐这种方式。




## 分层API

data stream api
process function api
最高层 sql api

## 批处理和流处理都支持，批流一体

batch application
stream application

## Flink如何以Table的概念支持批流一体

### 流到动态表的转换

动态表 是 Flink 的支持流数据的Table的核心概念。动态表的查询是一种永不停止的查询，动态表的查询结果也是一种永在变更的结果。

### 动态表到流的转换

* Append-only 流
* Retract 流
* Upsert 流： 与 retract 流的主要区别在于 UPDATE 操作是用单个 message 编码的，因此效率更高。



## keygroup

Flink的状态分为两类：Keyed State和Operator State。前者与每个键相关联，后者与每个算子的并行实例（即Sub-Task）相关联。

Key Group是Flink状态机制中的一个重要设计. Key Group是Keyed State分配的原子单位，且Flink作业内Key Group的数量与最大并行度相同，也就是说Key Group的索引位于[0, maxParallelism - 1]的区间内。 
从这里可以看到key-group与最大并发数有关系，如果key-group分配不均匀的话，状态分配也会不均匀。


## Catalog

Catalog 提供了元数据信息，例如数据库、表、分区、视图以及数据库或其他外部系统中存储的函数和信息。

Metastore 即元数据服务，是Hive用来管理库表元数据的一个服务


HiveCatalog(String catalogName, String defaultDatabase, String hiveConfDir, String hadoopConfDir, String hiveVersion) 








# Flink功能

## StreamExecutionEnvironment

每一个flink应用都需要一个执行环境， 对于流处理程序，使用的执行环境类是 StreamExecutionEnvironment.
当 env.execute() 方法执行之后，代码所设计的一张执行图就会被打包发送到Flink Master，进行任务拆解和并行化，分配到TaskManager执行。

## 几种stream

DataStream

SingleOutputStreamOperator


## Operator算子 DataStream Transformations

filter 过滤器，对数据流中的每个元素进行过滤判断，判断为true的元素进入下一个数据流
  RichFilterFunction

flatmap 可以理解为将元素摊平，每个元素可以变为0个、1个、或者多个元素。
  RichFlatMapFunction

map 可以理解为映射，对每个元素进行一定的变换后，映射为另一个元素。

mapPartition 维护每个并行分区内记录的顺序，
  RichMapPartitionFunction

name 方法Sets the name of the current data stream.

returns 方法Adds a type information hint about the return type of this operator.

keyby DataStream → KeyedStream	

key Agg

getSideOutput 侧输出

Evictor：可以译为“驱逐者”。在Trigger触发之后，在窗口被处理之前，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。


### join 和 coGroup 和 intervalJoin

join：是一个流join另一个流，需要设置窗口，2个流join需要的key字段。使用的是innerJoin。对Processing Time和Event Time都支持。

coGroup：和join类似，不过CoGroupFunction和JoinFunction的参数不一样。coGroup是需要自己组装数据。

intervalJoin：是一个流join另一个流，不需要设置窗口，但是需要设置流join的时间范围（需要时间字段），仅支持Event Time的计算。


> Join转换使用来自两个输入的匹配记录对调用JoinFunction,这两个输入具有相同的键字段值.此行为与相等的内部联接非常相似.
> CoGroup转换在具有相同键值字段的两个输入的所有记录上调用带有迭代器的CoGroupFunction.如果输入没有某个键值的记录,则传递空迭代器.除了别的以外,CoGroup转换可以用于内部和外部的相等连接.因此它比Join变换更通用.
> intervalJoin

https://developer.aliyun.com/article/778485


## 数据重分布

partitionCustom


## StatusBackend

Flink 提供了内存、文件系统、RocksDB 三种 StateBackends.
- MemoryStateBackend: 状态信息是存储在 TaskManager 的堆内存中的，checkpoint 的时候将状态保存到 JobManager 的堆内存中。
- FsStateBackend: TaskManager会定期地把state存到HDFS上。也就是checkpoint 的时候将状态保存到指定的文件中 (HDFS 等文件系统)。
- RocksDBStateBackend：状态信息存储在 RocksDB 数据库 (key-value 的数据存储服务)， 最终保存在本地文件中。checkpoint 的时候将状态保存到指定的文件中 (HDFS 等文件系统)。

关于超大状态存储策略选择，生产环境状态存储 Backend 有两种方式： 
- FsStateBackend： State 存储在内存， Checkpoint 时持久化到 HDFS； 
- RocksDBStateBackend： State 存储在 RocksDB 实例，可增量 Checkpoint ，适合超大 State。在推荐广告搜索等场景下展现流 20 分钟数据有 1 TB 以上。

参考： https://cloud.tencent.com/developer/article/1592441

参考: https://ci.apache.org/projects/flink/flink-docs-master/zh/docs/dev/datastream/fault-tolerance/checkpointing/

Checkpointed Function

ReducingStateDescriptor


## Checkpoint 

### Checkpoint 配置

- checkpoint interval
- checkpoint Timeout
- pause between checkpoints
- number of concurrent checkpoints

### Checkpoint 状态

- End to End Duration
- Checkpoint Counts: 包含Triggered: 1018 In Progress: 1 Completed: 1016 Failed: 1 Restored: 1

## window

Window是无限数据流处理的核心，Window将一个无限的stream拆分成有限大小的”buckets”桶，我们可以在这些桶上做计算操作。

分组的流 vs 非分组的流。唯一的区别是分组的stream调用keyBy(…)和window(…)，而非分组的stream中window()换成了windowAll(…)

- 滚动窗口合并 TumblingEventTimeWindows 
固定大小窗口，不重叠，一个贴一个，同一元素不会分配到多个窗口。
- 滑动窗口合并 SlidingEventTimeWindows
固定大小窗口，多了一个滑动参数，每次滑动都按滑动参数大小，窗口大小>滑动大小的话，就会有一部分重叠，落入重叠的元素会分配到多个窗口。
- Session窗口合并 EventTimeSessionWindows
不同流之间的窗口不是按时间分组的，而是按各自的session分组。session的划分是当固定时间周期内不受到元素，则窗口关闭。
- 间隔关联合并

PS:间隔关联目前只支持eventtime，只支持inner join.

官网对window的介绍 https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/joining.html

中文介绍 https://blog.csdn.net/dafei1288/article/details/98919202


### 窗口内处理

ProcessWindowFunction

## Event Time

setStreamTimeCharacteristic

- TimeCharacteristic.EventTime 
事件产生的时间，即数据产生时自带时间戳
- TimeCharacteristic.ProcessingTime
与数据本身的时间戳无关，即在window窗口内计算的时间（默认的Time）
- TimeCharacteristic.IngestionTime
数据进入到Flink的时间


## watermark

watermark是和Event Time一起使用的一个概念。由于消息自身的时间和消息被flink处理的时间往往是不同的，为了准备的表达数据的处理进度，出现了水印的概念。

水印就是一个时间戳，可以给每个消息添加一个 允许一定延迟 的时间戳。

watermark是用于处理乱序事件的，通常用watermark机制结合window来实现

水印是Flink判断迟到数据的标准，同时也是窗口触发的标记。

DataStream.assignTimestampsAndWatermarks()方法来提取事件时间并同时产生水印。

当我们把消息生产的时间戳赋值给水印值，就意味着水印值一定能够表示消息生产的先后顺序。

- 窗口可以继续计算一定时间范围内延迟的消息
- 添加水印后，窗口会等 5 秒，再执行计算。若超过5秒，则舍弃。
- 窗口执行计算时间由 水印时间 来触发，当接收到消息的 watermark >= endtime ，触发计算


AscendingTimestampExtractor的作用？
AscendingTimestampExtractor产生的时间戳和水印必须是单调非递减的，用户通过覆写extractAscendingTimestamp()方法抽取时间戳.

BoundedOutOfOrdernessTimestampExtractor 的作用？
BoundedOutOfOrdernessTimestampExtractor产生的时间戳和水印是允许“有界乱序”的，构造它时传入的参数maxOutOfOrderness就是乱序区间的长度，而实际发射的水印为通过覆写extractTimestamp()方法提取出来的时间戳减去乱序区间，相当于让水印把步调“放慢一点”。这是Flink为迟到数据提供的第一重保障。


需要深刻理解这几个概念才行 https://www.jianshu.com/p/c612e95a5028


## source

flink中的source作为整个stream中的入口，而sink作为整个stream的终点。

SourceFunction为所有flink中source的根接口，其定义了run()方法和cancel()方法。

- run方法的功能是核心功能，主要用于source往出emit元素
- cancel方法时用于取消run方法的执行，一般来说run方法内部是一个循环，cancel方法中控制run方法的循环不满足条件，从而取消run方法的执行。


addSource(sourceFunction)

SourceFunction、ParallelSourceFunction、RichParallelSourceFunction


## sink

Sink是流的重点，根接口是sinkFunction。

其重要的方法是invoke()方法，用以实现结果数据的处理逻辑

SinkFunction 是一个接口，类似于SourceFunction接口。SinkFunction中主要包含一个方法，那就是用于数据输出的invoke 方法,每条记录都会执行一次invoke方法，用于执行输出操作。

addSink(sinkFunction)


## Connector 

用于支持与其他组件数据连接的 source 和 sink。比如和kafka连接，比如和Hadoop连接，比如和RaddbitMQ连接。

其中最为常用的当属Flink kafka connector。

此外，Apache Bahir 项目中也提供了更多连接器。

### FlinkKafkaConsumer
kafka 中数据都是以二进制 byte 形式存储的。读到 Flink 系统中之后，需要将二进制数据转化为具体的 java、scala 对象。所以需要实现一个 schema 类，定义如何序列化和反序列数据。

反序列化时需要实现 DeserializationSchema 接口，并重写 deserialize(byte[] message) 函数。
如果是反序列化 kafka 中 kv 的数据时，需要实现 KeyedDeserializationSchema 接口，并重写 deserialize(byte[] messageKey, byte[] message, String topic, int partition, long offset) 函数。

- DeserializationSchema 接口类
下面是三个内置的常用序列化类
  * SimpleStringSchema，按字符串方式进行序列化、反序列化。
  * TypeInformationSerializationSchema，它可根据 Flink 的 TypeInformation 信息来推断出需要选择的 schema。
  * JsonDeserializationSchema 使用 jackson 反序列化 json 格式消息，并返回 ObjectNode，可以使用 .get(“property”) 方法来访问相应字段。



## Flink DDL



## Flink SQL

和传统SQL不同，Flink SQL设计成的是一个批流一体的SQL。 使得查询对于批（DataSet）和流（DataStream）的输入有相同的语义，也会产生同样的计算结果。
一直以来SQL都是用来处理关系型批量数据的，而不是处理流式数据。尽管存在这些差异，但是使用关系查询和 SQL 处理流并不是不可能的。

查询动态表将生成一个 连续查询 。一个连续查询永远不会终止，结果会生成一个动态表。查询不断更新其(动态)结果表，以反映其(动态)输入表上的更改。

动态表 (Dynamic Table): https://ci.apache.org/projects/flink/flink-docs-master/zh/dev/table/streaming/dynamic_tables.html

Flink SQL 工作机制: https://zhuanlan.zhihu.com/p/150473300

Flink SQL如何实现数据流的join： http://www.whitewood.me/2019/12/15/Flink-SQL-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E6%B5%81%E7%9A%84-Join/

Streaming SQL

批式模型和流式模式

- EnvironmentSettings.newInstance().useBlinkPlanner().inBatchMode().build()
- EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();

Table API 和 SQL API使用的差别

* executeSql
* sqlQuery 特定于select sql语句，其返回值是一个Table

- Table table2 = tableEnv.from("table1").select(...); // create a Table object from a Table API query
- Table table3 = tableEnv.sqlQuery("SELECT ... FROM table1 ... "); // create a Table object from a SQL query

批流一体的概念中，SQL是真正一体的，Environment、Source、Sink并不是一体的。

* 创建表(tablesource)：  
* 查询表
* 输出表(TableSink)： Table 通过写入 TableSink 输出。TableSink 是一个通用接口，用于支持多种文件格式（如 CSV、Apache Parquet、Apache Avro）、存储系统（如 JDBC、Apache HBase、Apache Cassandra、Elasticsearch）或消息队列系统（如 Apache Kafka、RabbitMQ）。批处理 Table 只能写入 BatchTableSink，而流处理 Table 需要指定写入 AppendStreamTableSink，RetractStreamTableSink 或者 UpsertStreamTableSink。


将流式概念转为批流一体的Table概念
不管流式数据源还是批式数据源，进入到Flink SQL里，都以table的概念来表达。
- tableEnv.createTemporaryView: 在 TableEnvironment 中可以将 DataStream 或 DataSet 注册成视图。结果视图的 schema 取决于注册的 DataStream 或 DataSet 的数据类型
- tableEnv.fromDataStream: DataStream 和 DataSet 还可以直接转换成 Table

table概念还可以再转回datastream
- tableEnv.toAppendStream
- tableEnv.toRetractStream



## Flink SQL建表

``` java
tableEnv.connect(new FileSystem().path(filePath))
.withFormat(new Csv()) //withFormat 是用来告诉flink我应该怎么处理来源用的每一条数据 比如按csv的格式,号分割
.withSchema(new Schema() //withSchema 是声明创建表的表结构 要按照解析得到的数据的先后顺序对应
.field("id", DataTypes.STRING())
.field("time", DataTypes.BIGINT())
.field("temp", DataTypes.DOUBLE()))
.createTemporaryTable("inputTable");
```

https://www.cnblogs.com/21airuirui1123/p/14644933.html


## UDF

### Table API/SQL UDF

- Scalar 函数， 将一个标量数据 转换成 一个标量数据。
- Table 函数， 将一个标量数据 转换成 数据。
- Aggregate 函数， 将多行的标量数据 聚合成为一个标量数据。
- Table aggregate 函数， 将多行的标量数据 聚合成 行数据。 
- Async table 函数， lookup。


### DataStreamAPI UDF


- 最基础的方式就是 implements MapFunction去实现一个新的类，或者是data.map(后面直接new MapFunction出一个匿名的类)
- Rich Function， 附加了open, close， getRuntimeContext, setRuntimeContext 四个方法。



## TableFactory
TableFactory 用来创建与table相关的实例工厂接口，实例的来源来自字符串形式的properties。

实现该接口的类应该被这样添加： Classes that implement this interface can be added to the "META_INF/services/org.apache.flink.table.factories.TableFactory" file of a JAR file in the current classpath to be found.

TableSourceFactory
tableSinkFactory





## DataSet API

1.12版本开始DataSetAPI正在废弃中。








# Flink部署

## standalone mode

mac环境下: 用brew安装flink， $ brew install apache-flink
* brew安装的flink会放置在 /usr/local/Cellar/apache-flink/1.9.1/libexec 

* ./libexec/bin/start-cluster.sh

* ./libexec/bin/stop-cluster.sh

## yarn mode


## kubernetes mode 

* 首先往 Kubernetes 集群提交了资源描述文件后，会启动 Master 和 Worker 的 container。
* Master Container 中会启动 Flink Master Process，包含 Flink-Container ResourceManager、JobManager 和 Program Runner。
* Worker Container 会启动 TaskManager，并向负责资源管理的 ResourceManager 进行注册，注册完成之后，由 JobManager 将具体的任务分给 Container，再由 Container 去执行。


# Flink监控

## Flink自带的dashboard

## flink自定义metric

flink metric类型分为Counter、Gauge、Histogram、Meter

第一，常用的如 Counter，写过 mapreduce 作业的开发人员就应该很熟悉 Counter，其实含义都是一样的，就是对一个计数器进行累加，即对于多条数据和多兆数据一直往上加的过程。
第二，Gauge，Gauge 是最简单的 Metrics，它反映一个值。比如要看现在 Java heap 内存用了多少，就可以每次实时的暴露一个 Gauge，Gauge 当前的值就是 heap 使用的量。
第三，Meter，Meter 是指统计吞吐量和单位时间内发生“事件”的次数。它相当于求一种速率，即事件次数除以使用的时间。
第四，Histogram，Histogram 比较复杂，也并不常用，Histogram 用于统计一些数据的分布，比如说 Quantile、Mean、StdDev、Max、Min 等。

https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/metrics.html

## Prometheus 监控flink metric


## 日志

JM日志

TM日志

flink custer log

flink jobs log

configuration trace log




# Flink集群资源规划

## CPU和内存

JobManager个数

TaskManager规格

TaskManager个数 

单个TaskManager槽位数

## Task slot

任务槽是Flink计算资源的基本单位. Task Manager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。
每个任务槽可以在同一时间执行一个Task，而TaskManager可以拥有一个或者多个任务槽。
任务槽可以实现TaskManager中不同Task的资源隔离，不过是逻辑隔离，并且只隔离内存，亦即在调度层面认为每个任务槽“应该”得到taskmanager.heap.size的N分之一大小的内存。CPU资源不算在内。

apus.slotmanager.slot-placement-policy  SLOT


## 并行度设定

设置parallelism的防范优先级是：算子(operator)级别 > 运行环境级别 > 客户端级别 > 系统级别

setParallelism 设置一个job或一个算子op的并发度。

setMaxParallelism 控制的是状态后端中keyed-state可以被分配的task最大个数。


## 特殊配置项

taskmanager.memory.task.off-heap.size 用于 Flink 应用的算计及用户代码的堆外内存（直接内存或本地内存）
akka.ask.timeout 阻塞操作，可能因为机器繁忙或者网络堵塞导致timeout,可以尝试设置大一点
akka.framesize   JM和TM之间传输的最大消息值
heartbeat.timeout
300000
restart-strategy
fixed-delay
restart-strategy.fixed-delay.delay
180s
restart-strategy.fixed-delay.attempts
1000
state.backend.rocksdb.timer-service.factory
ROCKSDB
env.java.opts.taskmanager.additional
-XX:MaxGCPauseMillis=300
taskmanager.network.request-backoff.max
60000
apus.taskmanager.network.request.wait.ms
30000
taskmanager.network.request-backoff.initial
20000
apus.memory.incontainer.available.ratio
0.9
cluster.evenly-spread-out-slots
true
apus.slotmanager.slot.placement.policy
slot
jobmanager.execution.failover-strategy
region
apus.log.separate.enabled
false



# Flink HelloWorld

下面是一些最为简单的例子程序

## Basic Commands

```shell
cd /usr/local/Cellar/apache-flink/1.9.1 && ./libexec/bin/start-cluster.sh

./bin/flink run -c com.aaa.worldcount xxx.jar --host localhost --port 7777

./bin/flink list --all

./bin/flink cancel job_id
```



## scala code

```java
import org.apache.flink.api.scala._

object FlinkWordCount {
  def main(args:Array[String]):Unit = {
    //val env = ExecutionEnvironment.getExecutionEnvironment;
    val env = ExecutionEnvironment.createRemoteEnvironment("flink-master", 6123, "D:\\CodeBase\\jvmlearning\\flink-learning\\target\\flink-learning-1.0-SNAPSHOT.jar")
    
	val text = env.readTextFile("hdfs://flink-master:9000/user/flink/input/SogouQ.sample")
    
	println(text.count())
    
	val counts = text.flatMap {  _.toLowerCase.split("\\W+") }
      .map { (_, 1) }
      .groupBy(0)
      .sum(1)
    
	//env.execute()
    println(counts.count())
    //println(env.getExecutionPlan());
    //counts.print()
  }
}
```



## java code

这是我在IDEA上编译运行的第一个flink程序（maven构建）。

可以通过在命令行 $ nc -lk 9000 来往flink程序里输入字节流。

```java
package myflink;
import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.util.Collector;

public class SocketWindowWordCount {
    public static void main(String[] args) throws Exception {
        // Create the execution environment.
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        // Get the input data by connecting the socket.
        // Here it is connected to the local port 9000.
        // If the port 9000 has been already occupied, change to another port.
        DataStream<String> text = env.socketTextStream("localhost", 9000, "\n");
        // Parse the data, and group, windowing and aggregate it by word.
        DataStream<Tuple2<String, Integer>> windowCounts = text
                .flatMap(new FlatMapFunction<String, Tuple2<String, Integer>>() {
                    @Override
                    public void flatMap(String value, Collector<Tuple2<String, Integer>> out) {
                        for (String word : value.split("\\s")) {
                            out.collect(Tuple2.of(word, 1));
                        }
                    }
                })
                .keyBy(0)
                .timeWindow(Time.seconds(10))
                .sum(1);
        // Print the results to the console, note that here it uses the single-threaded printing instead of multi-threading
        windowCounts.print().setParallelism(1);
        env.execute("Socket Window WordCount");
    }
}
```


```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        // 添加自定义数据源
        DataStreamSource<Person> data = env.addSource(new MyMysqlSource());
        data.print().setParallelism(2);
        data.addSink(new MyMysqlSink());
        // 提交执行任务
env.execute("MySourceMysql");
```


## Flink Job

首先你得把java或scala程序变成jar包，直接使用mave的package功能（注意maven指定的jdk版本要和运行时的版本一致）。

打开 http://localhost:8081/#/overview ，在Web界面提交job。

然后在Task Manager里面就可以看到自己提交的job，其日志和标准输出都可以看到。



# Flink背后的依赖库

- 组件间通信 akka ，JobManager和TaskManager之间的控制通信
- 数据传输 netty， 比如Operator之间的传输数据 https://github.com/wangzhiwubigdata/God-Of-BigData/tree/master/Netty


# Alink

Alink是基于Flink的通用算法平台 https://github.com/alibaba/Alink

FlinkML
FlinkML是1.8之前的一个机器学习组件，在1.9开始已经不存在了。
https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/libs/ml/index.html


## BatchOperator

## FlatMapStreamOp

## linkFrom && link


## PyAlink 和 Alink 的关系？

## PyAlink 和 pyFlink 的关系？
https://zhuanlan.zhihu.com/p/114717285 
https://github.com/uncleguanghui/pyflink_learn/blob/master/examples/README.md

PyFlink是 apache-flink项目里的一个还未成熟的部分。


# 参考

最权威的使用文档是：https://flink.apache.org/

最权威的底层实现文档是： Flink Internals https://cwiki.apache.org/confluence/display/FLINK/Flink+Internals

flink基本概念介绍 https://www.jianshu.com/p/2ee7134d7373

如何正确使用 flink connector https://yq.aliyun.com/articles/716838

idea+maven打jar包  https://blog.csdn.net/branwel/article/details/79918018

官网的内容超级全 https://ci.apache.org/projects/flink/flink-docs-release-1.10/

Flink如何支持特征工程、在线学习、在线预测等AI场景？ https://mp.weixin.qq.com/s/C2Uft-IuzgiKa1aDlROIng

快手的Flink实践 https://new.qq.com/omn/20190717/20190717A0HNBE00.html


## Flink Forward China 2019

## Flink Forward China 2020

failover单点恢复而不进行全局恢复

实时数仓

hudi 支持基于主键的upsert/delete

数据湖框架

PyFlink

Flink AL Extended
